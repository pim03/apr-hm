\documentclass[a4paper,12pt]{article} % This defines the style of your paper

\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry} 

% Unfortunately, LaTeX has a hard time interpreting German Umlaute. The following two lines and packages should help. If it doesn't work for you please let me know.
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{subcaption}

% The following two packages - multirow and booktabs - are needed to create nice looking tables.
\usepackage{multirow} % Multirow is for tables with multiple rows within one cell.
\usepackage{booktabs} % For even nicer tables.
\usepackage{amsmath}

% As we usually want to include some plots (.pdf files) we need a package for that.
\usepackage{graphicx} 
\usepackage{rotating}
\usepackage{cancel}

% The default setting of LaTeX is to indent new paragraphs. This is useful for articles. But not really nice for homework problem sets. The following command sets the indent to 0.
\usepackage{setspace}
\setlength{\parindent}{0in}

% Package to place figures where you want them.
\usepackage{float}

% The fancyhdr package let's us create nice headers.
\usepackage{fancyhdr}

\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{makecell}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\renewcommand{\arraystretch}{1.5}

\pagestyle{fancy} % With this command we can customize the header style.

\fancyhf{} % This makes sure we do not have other information in our header or footer.

\lhead{\footnotesize Homework 3}% \lhead puts text in the top left corner. \footnotesize sets our font to a smaller size.

%\rhead works just like \lhead (you can also use \chead)
\rhead{\footnotesize Joana Pimenta, Rodrigo Laia} %<---- Fill in your lastnames.

% Similar commands work for the footer (\lfoot, \cfoot and \rfoot).
% We want to put our page number in the center.
\cfoot{\footnotesize \thepage} 

\begin{document}

\thispagestyle{empty} % This command disables the header on the first page. 

\begin{tabular}{p{15.5cm}} % This is a simple tabular environment to align your text nicely 
{\large \bf Aprendizagem} \\
Instituto Superior Técnico \\ outubro  de 2023  \\ \\ 
\hline % \hline produces horizontal lines.
\\
\end{tabular} % Our tabular environment ends here.

\vspace*{0.3cm} % Now we want to add some vertical space in between the line and our title.

\begin{center} % Everything within the center environment is centered.
	{\Large \bf Homework 3 - Report} % <---- Don't forget to put in the right number
	\vspace{2mm}
	
        % YOUR NAMES GO HERE
	{\bf Joana Pimenta (103730), Rodrigo Laia (102674) } % <---- Fill in your names here!
		
\end{center}  

\vspace{0.4cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Up until this point you only have to make minor changes for every week (Number of the homework). Your write up essentially starts here.

\section*{Pen and Paper}
\begin{enumerate}

\item 

% \begin{table}[H]
% \centering
% \begin{tabular}{|c|c|c|c|}
% \hline
%  & $y_1$ & $y_2$ & $y_{out}$ \\ \hline
% $x_1$ & 0.7 & -0.3 & 0.8 \\ \hline
% $x_2$ & 0.4 & 0.5 & 0.6 \\ \hline
% $x_3$ & -0.2 & 0.8 & 0.3 \\ \hline
% $x_4$ & -0.4 & 0.3 & 0.3 \\ \hline
% \end{tabular}
% \end{table}


%%%%%%%%%%%%%%%%%% a) %%%%%%%%%%%%%%%%%%%

a) Uma função radial basis permite mapear observações para um novo espaço 
baseando-se na distância entre as observações e os centróides.

\begin{equation}
    \phi_j (x) = \exp\left(-\frac{\left\|\vec{x}-c_j\right\|^2}{2}\right)
\end{equation}

Cálculo dos vetores transformados:

\begin{equation}
\vec{\phi_i} = \left( \exp\left(-\frac{\left\|\vec{x}_i-c_1\right\|^2}{2}\right)   , \exp\left(-\frac{\left\|\vec{x}_i-c_2\right\|^2}{2}\right)  , \exp\left(-\frac{\left\|\vec{x}_i-c_3\right\|^2}{2}\right)   \right)
\end{equation}

Assim os vetores transformados obtidos foram:
\begin{equation*}
    \phi_1 = (0.74826,0.74826,0.10127)
\end{equation*}

\begin{equation*}
    \phi_2 = (0.81465,0.27117,0.33121)
\end{equation*}

\begin{equation*}
    \phi_3 = (0.71177,0.09633,0.71177)
\end{equation*}

Para fazer regressão de Ridge é necessário minimizar a função de erro:

\begin{equation}
    E(\vec{w}) = \frac{1}{2} \sum_{i=1}^{n} (z_i - \vec{w}^T \cdot x_i)^2 + \frac{\lambda}{2} ||\vec{w}||^2
\end{equation}

Sendo que isso é equivalente a calcular $\vec{w}$ através da seguinte fórmula:

\begin{equation}
    \vec{w} = (X^T\cdot X + \lambda \cdot I)^{-1} \cdot X^T \cdot \vec{z}
\end{equation}

Uma vez que estamos a trabalhar com uma transformação de espaços, é necessário
calcular a matriz transformada $\Phi$ colocando para cada linha um 1 na primeira
coluna e depois o vetor transformado de cada observação. Utilizamos então as 
fórmulas acima com $\Phi$ no lugar de $X$, assumindo que após a transformação a 
relação entre as variáveis e o target é linear.\\ 

Cálculos intermédios:

\begin{equation*}
    \Phi = 
\begin{bmatrix}
    1 & 0.74826 & 0.74826 & 0.10127 \\ 1 & 0.81465 & 0.27117 & 0.33121 \\ 1 & 0.71177 & 0.09633 & 0.71177 \\ 1 & 0.88250 & 0.16122 & 0.65377
\end{bmatrix}
\end{equation*}

\begin{equation*}
    \Phi^T = \begin{bmatrix}
    1 & 1 & 1 & 1 \\ 0.74826 & 0.81465 & 0.71177 & 0.88250 \\ 0.74826 & 0.27117 & 0.09633 & 0.16122 \\ 0.10127 & 0.33121 & 0.71177 & 0.65377
    \end{bmatrix}
\end{equation*}

\begin{equation*}
    (\Phi^T\cdot \Phi + \lambda \cdot I)^{-1} \cdot \Phi^T = \begin{bmatrix}  0.14105 & 0.35022 & 0.35575 & -0.30185 \\
        -0.09064 & 0.43823 & -0.50361 & 0.53370 \\
         0.99394 & -0.50615  & -0.13690 & -0.16477 \\
        -0.31222 & -0.65246 & 0.72647  &  0.42436 \\ \end{bmatrix}
\end{equation*}

\begin{equation*}
    \vec{w} = \begin{bmatrix}  0.33914 \\ 0.19945 \\ 0.40096 \\ -0.29600 \end{bmatrix}
\end{equation*}

Assim, a regressão de Ridge obtida foi:

\begin{equation*}  
    \hat{z} = 0.33914 + 0.19945 \cdot \phi_1 + 0.40096 \cdot \phi_2 - 0.29600 \cdot \phi_3
\end{equation*}

%%%%%%%%%%%%%%%%%% b) %%%%%%%%%%%%%%%%%%%
b)
Para calcular o RMSE (root mean square error) foi utilizada a seguinte fórmula:

\begin{equation}
    RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (z_i - \hat{z}_i)^2}
\end{equation}

\begin{equation}
    \hat{z}_i = \vec{w}^T \cdot \vec{\phi_i}
\end{equation}
 
Targets estimados:
\begin{equation*}
    \hat{z}_1 = 0.75843
\end{equation*}

\begin{equation*}
    \hat{z}_2 = 0.51231
\end{equation*}

\begin{equation*}
    \hat{z}_3 = 0.30905
\end{equation*}

\begin{equation*}
    \hat{z}_4 = 0.38629
\end{equation*}

Assim, o RMSE obtido foi:
\begin{equation*}
    RMSE = 0.06508
\end{equation*}

\item
É importante referir que para este exercício se utilizou a seguinte notação: $L^{\text{label}}_{observation}$

As fórmulas utilizadas foram:

\begin{equation*}
    \vec{x}^{[p]} = \phi(\vec{W}^{[p]} \cdot \vec{x}^{[p-1]} + \vec{b}^{[p]})
\end{equation*}

\begin{equation*}
    \vec{\delta}^{[p]} = \frac{\partial E}{\partial \vec{x}^{[p]}} \circ \frac{\partial \vec{x}^{[p]}}{\partial \vec{z}^{[p]}} = (\vec{x}^{[p]} - \vec{t}) \circ \phi'(\vec{z}^{[p]}) \text{, para a última layer}
\end{equation*}

\begin{equation*}
    \vec{\delta}^{[p]} = (\frac{\partial \vec{z}^{[p+1]}}{\partial \vec{x}^{[p]}})^T \cdot \vec{\delta}^{[p+1]} \circ \frac{\partial \vec{x}^{[p]}}{\partial \vec{z}^{[p]}} = (\vec{W}^{[p+1]})^T \cdot \vec{\delta}^{[p+1]} \circ \phi'(\vec{z}^{[p]}) \text{, para as outras layers}
\end{equation*}

\begin{equation*}
    \vec{W}^{[p]} = \vec{W}^{[p]} - \eta \cdot \frac{\partial E}{\partial \vec{W}^{[p]}} = \vec{W}^{[p]} - \eta \cdot \vec{\delta}^{[p]} \cdot (\vec{x}^{[p-1]})^T
\end{equation*}

\begin{equation*}
    \vec{b}^{[p]} = \vec{b}^{[p]} - \eta \cdot \frac{\partial E}{\partial \vec{b}^{[p]}} = \vec{b}^{[p]} - \eta \cdot \vec{\delta}^{[p]}
\end{equation*}

Estas expressões são válidas para squared error loss function.

Dados necessários para começar o algoritmo:

\begin{equation*}
    \vec{x}^{[0]}_1 = \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix} , t_1 = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix} , \vec{x}^{[0]}_2 = \begin{bmatrix} 1 \\ 0 \\ 0 \\ -1 \end{bmatrix} , t_2 = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}
\end{equation*}

\begin{equation*}
    W^{[1]} = \begin{bmatrix} 1 & 1 & 1 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 1 & 1 & 1 \end{bmatrix} , b^{[1]} = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}, W^{[2]} = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 4 & 1 \end{bmatrix} , b^{[2]} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, W^{[3]} = \begin{bmatrix} 1 & 1 \\ 3 & 1 \\ 1 & 1 \end{bmatrix} , b^{[3]} = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}
\end{equation*}

\begin{equation*}
    \phi = tanh(0.5x -2) \text{, } \phi' = 0.5 * (1 - tanh^2(0.5x -2))
\end{equation*}

POR GUIA DE REDE!!!!!!!!

Primeiro é necessário realizar (forward) propagation para obter os valores das observações:

- Para a primeira observação:

\begin{equation*}
    z^{[1]}_1 = W^{[1]} \cdot x^{[0]}_1 + b^{[1]} = \begin{bmatrix} 5 \\ 6 \\ 5 \end{bmatrix} \implies x^{[1]}_1 = \phi(z^{[1]}_1)= \begin{bmatrix} 0.46212 \\ 0.76159 \\ 0.46212 \end{bmatrix}
\end{equation*}

\begin{equation*}
    z^{[2]}_1 = W^{[2]} \cdot x^{[1]}_1 + b^{[2]} = \begin{bmatrix} 2.68583 \\ 4.97061 \end{bmatrix} \implies x^{[2]}_1 = \phi(z^{[2]}_1)= \begin{bmatrix} -0.57642 \\ 0.45048 \end{bmatrix}
\end{equation*}

\begin{equation*}
    z^{[3]}_1 = W^{[3]} \cdot x^{[2]}_1 + b^{[3]} = \begin{bmatrix} 0.87406 \\ -0.27878 \\ 0.87406 \end{bmatrix} \implies x^{[3]}_1 = \phi(z^{[3]}_1)= \begin{bmatrix} -0.9159 \\ -0.97266 \\ -0.9159 \end{bmatrix}
\end{equation*}

- Para a segunda observação:

\begin{equation*}
    z^{[1]}_2 = W^{[1]} \cdot x^{[0]}_2 + b^{[1]} = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} \implies x^{[1]}_2 = \phi(z^{[1]}_2)= \begin{bmatrix} -0.90515 \\ -0.90515 \\ -0.90515 \end{bmatrix}
\end{equation*}

\begin{equation*}
    z^{[2]}_2 = W^{[2]} \cdot x^{[1]}_2 + b^{[2]} = \begin{bmatrix} -1.71545 \\ -4.43089 \end{bmatrix} \implies x^{[2]}_2 = \phi(z^{[2]}_2)= \begin{bmatrix} -0.99343 \\ -0.99956 \end{bmatrix}
\end{equation*}

\begin{equation*}
    z^{[3]}_2 = W^{[3]} \cdot x^{[2]}_2 + b^{[3]} = \begin{bmatrix} -0.992996 \\ -2.979861 \\ -0.992996 \end{bmatrix} \implies x^{[3]}_2 = \phi(z^{[3]}_2)= \begin{bmatrix} -0.98652 \\ -0.99814\\ -0.98652 \end{bmatrix}
\end{equation*}

Depois é necessário realizar (backward) propagation dos erros da última camada para a primeira:

- Para a primeira observação:

\begin{equation*}
    \delta^{[3]}_1 = (x^{[3]}_1 - t_1) \circ \phi'(z^{[3]}_1) = \begin{bmatrix} -0.07379 \\ -0.05320 \\ -0.07379 \end{bmatrix}
\end{equation*}

\begin{equation*}
    \delta^{[2]}_1 = (W^{[3]})^T \cdot \delta^{[3]}_1 \circ \phi'(z^{[2]}_1) = \begin{bmatrix} -0.10255 \\ -0.08001 \end{bmatrix}
\end{equation*}

\begin{equation*}
    \delta^{[1]}_1 = (W^{[2]})^T \cdot \delta^{[2]}_1 \circ \phi'(z^{[1]}_1) = \begin{bmatrix} -0.07179 \\ -0.08874 \\ -0.07179 \end{bmatrix}
\end{equation*}

- Para a segunda observação:

\begin{equation*}
    \delta^{[3]}_2 = (x^{[3]}_2 - t_2) \circ \phi'(z^{[3]}_2) = \begin{bmatrix} -0.026596 \\ -0.001854 \\ -0.01321 \end{bmatrix}
\end{equation*}

\begin{equation*}
    \delta^{[2]}_2 = (W^{[3]})^T \cdot \delta^{[3]}_2 \circ \phi'(z^{[2]}_2) = \begin{bmatrix} -2.9697\cdot 10^{-4} \\ -1.8157\cdot 10^{-5} \end{bmatrix}
\end{equation*}

\begin{equation*}
    \delta^{[1]}_2 = (W^{[2]})^T \cdot \delta^{[2]}_2 \circ \phi'(z^{[1]}_2) = \begin{bmatrix} -2.8473\cdot 10^{-5} \\ -3.3395\cdot 10^{-5} \\ -2.8473\cdot 10^{-5} \end{bmatrix}
\end{equation*}

Por fim é necessário atualizar os pesos e os bias. Como estamos a realizar um batch gradient descent update (with learning rate 0.1), a expressão para os pesos atualizados é dada por:

\begin{equation*}
    W^{[p]} = W^{[p]} - \eta \cdot (\delta^{[p]}_1 \cdot (x^{[p-1]}_1)^T + \delta^{[p]}_2 \cdot (x^{[p-1]}_2)^T)
\end{equation*}

\begin{equation*}
    W^{[1]} = W^{[1]} - 0.1 \cdot (\delta^{[1]}_1 \cdot (x^{[0]}_1)^T + \delta^{[1]}_2 \cdot (x^{[0]}_2)^T) = \begin{bmatrix} 1.0071818 & 1.00717895 & 1.00717895 & 1.00717611 \\
                                                                                                                            1.00887759 & 1.00887425 & 2.00887425 & 1.00887091 \\
                                                                                                                            1.0071818 & 1.00717895 & 1.00717895 & 1.00717611 \end{bmatrix}
\end{equation*}

\begin{equation*}
    b^{[1]} = b^{[1]} - 0.1 \cdot (\delta^{[1]}_1 + \delta^{[1]}_2) = \begin{bmatrix} 1.0071818 \\ 1.00887759 \\ 1.0071818 \end{bmatrix}
\end{equation*}

\begin{equation*}
    W^{[2]} = W^{[2]} - 0.1 \cdot (\delta^{[2]}_1 \cdot (x^{[1]}_1)^T + \delta^{[2]}_2 \cdot (x^{[1]}_2)^T) = \begin{bmatrix} 1.00471224 & 1.00778345 & 1.00471224 \\
                                                                                                                            1.00369595 & 4.00609219 & 1.00369595 \end{bmatrix}
\end{equation*}

\begin{equation*}
    b^{[2]} = b^{[2]} - 0.1 \cdot (\delta^{[2]}_1 + \delta^{[2]}_2) = \begin{bmatrix} 1.01028494 \\ 1.00800323 \end{bmatrix}
\end{equation*}

\begin{equation*}
    W^{[3]} = W^{[3]} - 0.1 \cdot (\delta^{[3]}_1 \cdot (x^{[2]}_1)^T + \delta^{[3]}_2 \cdot (x^{[2]}_2)^T) = \begin{bmatrix} 0.99310456 & 1.00066557 \\
                                                                                                                            2.99674951 & 1.00221106 \\
                                                                                                                            0.99443459 & 1.00200382 \end{bmatrix}
\end{equation*}

\begin{equation*}
    b^{[3]} = b^{[3]} - 0.1 \cdot (\delta^{[3]}_1 + \delta^{[3]}_2) = \begin{bmatrix} 1.01003842 \\ 1.00550496 \\ 1.00869959 \end{bmatrix}
\end{equation*}

\end{enumerate}

\clearpage
\section*{Programming - Código Python e Resultados Obtidos}

\begin{enumerate}
\item 

\end{enumerate}

\end{document}
